Index: gfx/cairo/libpixman/src/pixman-mmx.c
===================================================================
RCS file: /cvsroot/mozilla/gfx/cairo/libpixman/src/pixman-mmx.c,v
retrieving revision 1.13
diff -u -8 -p -r1.13 pixman-mmx.c
--- gfx/cairo/libpixman/src/pixman-mmx.c	7 Apr 2008 05:07:39 -0000	1.13
+++ gfx/cairo/libpixman/src/pixman-mmx.c	11 Oct 2008 07:54:41 -0000
@@ -30,27 +30,31 @@
  */
 
 #ifdef HAVE_CONFIG_H
 #include <config.h>
 #endif
 
 #ifdef USE_MMX
 
+#if _M_IX86_FP >= 1
+#define USE_SSE
+#endif
+
 #include <mmintrin.h>
 #ifdef USE_SSE
 #include <xmmintrin.h> /* for _mm_shuffle_pi16 and _MM_SHUFFLE */
 #endif
 
 #include "pixman-mmx.h"
 
 #undef READ
 #undef WRITE
 #define READ(img,x) *(x)
-#define WRITE(img,ptr,v) (*(ptr) = (v));
+#define WRITE(img,ptr,v) (*(ptr) = (v))
 
 #define noVERBOSE
 
 #ifdef VERBOSE
 #define CHECKPOINT() ErrorF ("at %s %d\n", __FUNCTION__, __LINE__)
 #else
 #define CHECKPOINT()
 #endif
@@ -338,28 +342,30 @@ in_over (__m64 src,
 #define in_over(src, srca, mask, dest) over(in(src, mask), pix_multiply(srca, mask), dest)
 #endif
 
 static inline __m64
 load8888 (uint32_t v)
 {
     return _mm_unpacklo_pi8 (_mm_cvtsi32_si64 (v), _mm_setzero_si64());
 }
+#define load8888(v) _mm_unpacklo_pi8(_mm_cvtsi32_si64(v), mZero)
 
 static inline __m64
 pack8888 (__m64 lo, __m64 hi)
 {
     return _mm_packs_pu16 (lo, hi);
 }
 
 static inline uint32_t
 store8888 (__m64 v)
 {
     return _mm_cvtsi64_si32(pack8888(v, _mm_setzero_si64()));
 }
+#define store8888(v) _mm_cvtsi64_si32(pack8888(v, mZero))
 
 /* Expand 16 bits positioned at @pos (0-3) of a mmx register into
  *
  *    00RR00GG00BB
  *
  * --- Expanding 565 in the low word ---
  *
  * m = (m << (32 - 3)) | (m << (16 - 5)) | m;
@@ -453,16 +459,18 @@ pix_add_mul (__m64 x, __m64 a, __m64 y, 
 #endif
 
 /* --------------- MMX code patch for fbcompose.c --------------------- */
 
 static FASTCALL void
 mmxCombineMaskU (uint32_t *src, const uint32_t *mask, int width)
 {
     const uint32_t *end = mask + width;
+    const __m64 mZero = _mm_setzero_si64();
+
     while (mask < end) {
         uint32_t mmask = *mask;
 	uint32_t maska = mmask >> 24;
 	if (maska == 0) {
 	    *src = 0;
 	} else if (maska != 0xff) {
 	    __m64 a = load8888(mmask);
 	    __m64 s = load8888(*src);
@@ -476,54 +484,57 @@ mmxCombineMaskU (uint32_t *src, const ui
     _mm_empty();
 }
 
 
 static FASTCALL void
 mmxCombineOverU (uint32_t *dest, const uint32_t *src, int width)
 {
     const uint32_t *end = dest + width;
+    const __m64 mZero = _mm_setzero_si64();
+    const __m64 mmx_4x00ff = MC(4x00ff);
 
     while (dest < end) {
 	uint32_t ssrc = *src;
-	uint32_t a = ssrc >> 24;
-	if (a == 0xff) {
+	if (ssrc >= 0xff000000) {
 	    *dest = ssrc;
-	} else if (a) {
+	} else if (ssrc > 0x00ffffff) {
 	    __m64 s, sa;
 	    s = load8888(ssrc);
 	    sa = expand_alpha(s);
-	    *dest = store8888(over(s, sa, load8888(*dest)));
+	    *dest = store8888(_mm_adds_pu8(s, pix_multiply(load8888(*dest), _mm_xor_si64(sa, mmx_4x00ff))));
 	}
 	++dest;
 	++src;
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineOverReverseU (uint32_t *dest, const uint32_t *src, int width)
 {
     const uint32_t *end = dest + width;
+    const __m64 mZero = _mm_setzero_si64();
 
     while (dest < end) {
 	__m64 d, da;
 	d = load8888(*dest);
 	da = expand_alpha(d);
 	*dest = store8888(over (d, da, load8888(*src)));
         ++dest;
         ++src;
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineInU (uint32_t *dest, const uint32_t *src, int width)
 {
     const uint32_t *end = dest + width;
+    const __m64 mZero = _mm_setzero_si64();
 
     while (dest < end) {
         __m64 x, a;
         x = load8888(*src);
         a = load8888(*dest);
         a = expand_alpha(a);
         x = pix_multiply(x, a);
         *dest = store8888(x);
@@ -532,16 +543,17 @@ mmxCombineInU (uint32_t *dest, const uin
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineInReverseU (uint32_t *dest, const uint32_t *src, int width)
 {
     const uint32_t *end = dest + width;
+    const __m64 mZero = _mm_setzero_si64();
 
     while (dest < end) {
         __m64 x, a;
         x = load8888(*dest);
         a = load8888(*src);
         a = expand_alpha(a);
         x = pix_multiply(x, a);
         *dest = store8888(x);
@@ -550,16 +562,17 @@ mmxCombineInReverseU (uint32_t *dest, co
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineOutU (uint32_t *dest, const uint32_t *src, int width)
 {
     const uint32_t *end = dest + width;
+    const __m64 mZero = _mm_setzero_si64();
 
     while (dest < end) {
         __m64 x, a;
         x = load8888(*src);
         a = load8888(*dest);
         a = expand_alpha(a);
         a = negate(a);
         x = pix_multiply(x, a);
@@ -569,16 +582,17 @@ mmxCombineOutU (uint32_t *dest, const ui
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineOutReverseU (uint32_t *dest, const uint32_t *src, int width)
 {
     const uint32_t *end = dest + width;
+    const __m64 mZero = _mm_setzero_si64();
 
     while (dest < end) {
         __m64 x, a;
         x = load8888(*dest);
         a = load8888(*src);
         a = expand_alpha(a);
         a = negate(a);
         x = pix_multiply(x, a);
@@ -588,16 +602,17 @@ mmxCombineOutReverseU (uint32_t *dest, c
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineAtopU (uint32_t *dest, const uint32_t *src, int width)
 {
     const uint32_t *end = dest + width;
+    const __m64 mZero = _mm_setzero_si64();
 
     while (dest < end) {
         __m64 s, da, d, sia;
         s = load8888(*src);
         d = load8888(*dest);
         sia = expand_alpha(s);
         sia = negate(sia);
         da = expand_alpha(d);
@@ -608,16 +623,17 @@ mmxCombineAtopU (uint32_t *dest, const u
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineAtopReverseU (uint32_t *dest, const uint32_t *src, int width)
 {
     const uint32_t *end;
+    const __m64 mZero = _mm_setzero_si64();
 
     end = dest + width;
 
     while (dest < end) {
         __m64 s, dia, d, sa;
         s = load8888(*src);
         d = load8888(*dest);
         sa = expand_alpha(s);
@@ -630,16 +646,17 @@ mmxCombineAtopReverseU (uint32_t *dest, 
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineXorU (uint32_t *dest, const uint32_t *src, int width)
 {
     const uint32_t *end = dest + width;
+    const __m64 mZero = _mm_setzero_si64();
 
     while (dest < end) {
         __m64 s, dia, d, sia;
         s = load8888(*src);
         d = load8888(*dest);
         sia = expand_alpha(s);
         dia = expand_alpha(d);
         sia = negate(sia);
@@ -647,36 +664,71 @@ mmxCombineXorU (uint32_t *dest, const ui
 	s = pix_add_mul (s, dia, d, sia);
         *dest = store8888(s);
         ++dest;
         ++src;
     }
     _mm_empty();
 }
 
+#ifdef _MSC_VER
+__declspec(naked)
+#endif
 static FASTCALL void
 mmxCombineAddU (uint32_t *dest, const uint32_t *src, int width)
 {
+#ifdef _MSC_VER
+    __asm {
+        mov     eax, [esp+12]
+        mov     edx, [esp+4]
+        mov     ecx, [esp+8]
+
+        test    eax, eax
+        jz      $toend
+
+align 16
+$add_loop:
+        cmp     dword ptr [ecx], 0
+        jz      $counter
+
+        movd    mm0, dword ptr [ecx]
+        movd    mm1, dword ptr [edx]
+        paddusb mm0, mm1
+        movd    dword ptr [edx], mm0
+
+$counter:
+        add     ecx, 4
+        add     edx, 4
+        sub     eax, 1
+        jnz     $add_loop
+
+        emms
+$toend:
+        ret
+    }
+#else
     const uint32_t *end = dest + width;
     while (dest < end) {
         __m64 s, d;
         s = load8888(*src);
         d = load8888(*dest);
         s = pix_add(s, d);
         *dest = store8888(s);
         ++dest;
         ++src;
     }
     _mm_empty();
+#endif
 }
 
 static FASTCALL void
 mmxCombineSaturateU (uint32_t *dest, const uint32_t *src, int width)
 {
     const uint32_t *end = dest + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (dest < end) {
         uint32_t s = *src;
         uint32_t d = *dest;
         __m64 ms = load8888(s);
         __m64 md = load8888(d);
         uint32_t sa = s >> 24;
         uint32_t da = ~d >> 24;
 
@@ -693,32 +745,34 @@ mmxCombineSaturateU (uint32_t *dest, con
     _mm_empty();
 }
 
 
 static FASTCALL void
 mmxCombineSrcC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         s = pix_multiply(s, a);
         *dest = store8888(s);
         ++src;
         ++mask;
         ++dest;
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineOverC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         __m64 d = load8888(*dest);
         __m64 sa = expand_alpha(s);
 
 	*dest = store8888(in_over (s, sa, a, d));
 
@@ -728,16 +782,17 @@ mmxCombineOverC (uint32_t *dest, uint32_
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineOverReverseC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         __m64 d = load8888(*dest);
         __m64 da = expand_alpha(d);
 
 	*dest = store8888(over (d, da, in (s, a)));
 
@@ -748,16 +803,17 @@ mmxCombineOverReverseC (uint32_t *dest, 
     _mm_empty();
 }
 
 
 static FASTCALL void
 mmxCombineInC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         __m64 d = load8888(*dest);
         __m64 da = expand_alpha(d);
         s = pix_multiply(s, a);
         s = pix_multiply(s, da);
         *dest = store8888(s);
@@ -767,16 +823,17 @@ mmxCombineInC (uint32_t *dest, uint32_t 
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineInReverseC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         __m64 d = load8888(*dest);
         __m64 sa = expand_alpha(s);
         a = pix_multiply(a, sa);
         d = pix_multiply(d, a);
         *dest = store8888(d);
@@ -786,16 +843,17 @@ mmxCombineInReverseC (uint32_t *dest, ui
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineOutC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         __m64 d = load8888(*dest);
         __m64 da = expand_alpha(d);
         da = negate(da);
         s = pix_multiply(s, a);
         s = pix_multiply(s, da);
@@ -806,16 +864,17 @@ mmxCombineOutC (uint32_t *dest, uint32_t
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineOutReverseC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         __m64 d = load8888(*dest);
         __m64 sa = expand_alpha(s);
         a = pix_multiply(a, sa);
         a = negate(a);
         d = pix_multiply(d, a);
@@ -826,16 +885,17 @@ mmxCombineOutReverseC (uint32_t *dest, u
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineAtopC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         __m64 d = load8888(*dest);
         __m64 da = expand_alpha(d);
         __m64 sa = expand_alpha(s);
         s = pix_multiply(s, a);
         a = pix_multiply(a, sa);
@@ -848,16 +908,17 @@ mmxCombineAtopC (uint32_t *dest, uint32_
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineAtopReverseC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         __m64 d = load8888(*dest);
         __m64 da = expand_alpha(d);
         __m64 sa = expand_alpha(s);
         s = pix_multiply(s, a);
         a = pix_multiply(a, sa);
@@ -870,16 +931,17 @@ mmxCombineAtopReverseC (uint32_t *dest, 
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineXorC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         __m64 d = load8888(*dest);
         __m64 da = expand_alpha(d);
         __m64 sa = expand_alpha(s);
         s = pix_multiply(s, a);
         a = pix_multiply(a, sa);
@@ -893,16 +955,17 @@ mmxCombineXorC (uint32_t *dest, uint32_t
     }
     _mm_empty();
 }
 
 static FASTCALL void
 mmxCombineAddC (uint32_t *dest, uint32_t *src, uint32_t *mask, int width)
 {
     const uint32_t *end = src + width;
+    const __m64 mZero = _mm_setzero_si64();
     while (src < end) {
         __m64 a = load8888(*mask);
         __m64 s = load8888(*src);
         __m64 d = load8888(*dest);
         s = pix_multiply(s, a);
         d = pix_add(s, d);
         *dest = store8888(d);
         ++src;
@@ -920,17 +983,17 @@ fbComposeSetupMMX(void)
     if (initialized)
 	return;
     
     /* check if we have MMX support and initialize accordingly */
     if (pixman_have_mmx())
     {
         pixman_composeFunctions.combineU[PIXMAN_OP_OVER] = mmxCombineOverU;
         pixman_composeFunctions.combineU[PIXMAN_OP_OVER_REVERSE] = mmxCombineOverReverseU;
-        pixman_composeFunctions.combineU[PIXMAN_OP_IN] = mmxCombineInU;
+        /* pixman_composeFunctions.combineU[PIXMAN_OP_IN] = mmxCombineInU; */
         pixman_composeFunctions.combineU[PIXMAN_OP_IN_REVERSE] = mmxCombineInReverseU;
         pixman_composeFunctions.combineU[PIXMAN_OP_OUT] = mmxCombineOutU;
         pixman_composeFunctions.combineU[PIXMAN_OP_OUT_REVERSE] = mmxCombineOutReverseU;
         pixman_composeFunctions.combineU[PIXMAN_OP_ATOP] = mmxCombineAtopU;
         pixman_composeFunctions.combineU[PIXMAN_OP_ATOP_REVERSE] = mmxCombineAtopReverseU;
         pixman_composeFunctions.combineU[PIXMAN_OP_XOR] = mmxCombineXorU;
         pixman_composeFunctions.combineU[PIXMAN_OP_ADD] = mmxCombineAddU;
         pixman_composeFunctions.combineU[PIXMAN_OP_SATURATE] = mmxCombineSaturateU;
@@ -949,16 +1012,60 @@ fbComposeSetupMMX(void)
 
         pixman_composeFunctions.combineMaskU = mmxCombineMaskU;
     }
 
     initialized = TRUE;
 }
 
 
+#ifdef _MSC_VER
+void
+pixman_fill32_omp (uint32_t *bits,
+         int       stride,
+         int       x,
+         int       y,
+         int       width,
+         int       height,
+         uint32_t  xor)
+{
+#ifdef _OPENMP
+    int h;
+
+    bits = bits + y * stride + x;
+
+#pragma omp parallel for
+    for (h = 0; h < height; h++)
+    {
+        int i;
+        uint32_t *dw = bits + stride * h;
+
+        for (i = 0; i < width; ++i)
+            dw[i] = xor;
+    }
+#else
+    int i;
+
+    bits = bits + y * stride + x;
+
+    while (height--)
+    {
+        for (i = 0; i < width; ++i)
+            bits[i] = xor;
+
+        bits += stride;
+    }
+#endif /* _OPENMP */
+}
+#endif /* _MSC_VER */
+
+
+#undef load8888
+#undef store8888
+
 /* ------------------ MMX code paths called from fbpict.c ----------------------- */
 
 void
 fbCompositeSolid_nx8888mmx (pixman_op_t op,
 			    pixman_image_t * pSrc,
 			    pixman_image_t * pMask,
 			    pixman_image_t * pDst,
 			    int16_t	xSrc,
@@ -1030,16 +1137,133 @@ fbCompositeSolid_nx8888mmx (pixman_op_t 
 	    dst++;
 	}
     }
 
     _mm_empty();
 }
 
 void
+fbCompositeSolid_nx8888mmx_omp (pixman_op_t op,
+			    pixman_image_t * pSrc,
+			    pixman_image_t * pMask,
+			    pixman_image_t * pDst,
+			    int16_t	xSrc,
+			    int16_t	ySrc,
+			    int16_t	xMask,
+			    int16_t	yMask,
+			    int16_t	xDst,
+			    int16_t	yDst,
+			    uint16_t	width,
+			    uint16_t	height)
+{
+#if defined(_OPENMP) && defined(_MSC_VER)
+    if (omp_cpu_counts >= 2 &&
+        width * height >= 150000)
+    {
+        uint32_t	src;
+        uint32_t	*dstLine;
+        int	dstStride;
+        __m64	vsrc, vsrca;
+        int i;
+
+        CHECKPOINT();
+
+        fbComposeGetSolid(pSrc, src, pDst->bits.format);
+
+        if (src >> 24 == 0)
+      return;
+
+        fbComposeGetStart (pDst, xDst, yDst, uint32_t, dstStride, dstLine, 1);
+
+        vsrc = load8888 (src);
+        vsrca = expand_alpha (vsrc);
+
+#pragma omp parallel
+        {
+#pragma omp for
+            for (i = 0; i < height; i++)
+            {
+                uint32_t *dst = dstLine + dstStride * i;
+                uint16_t w = width;
+
+                CHECKPOINT();
+
+                while (w && (unsigned long)dst & 7)
+                {
+                    *dst = store8888(over(vsrc, vsrca, load8888(*dst)));
+
+                    w--;
+                    dst++;
+                }
+
+                while (w >= 2)
+                {
+                    __m64 vdest;
+                    __m64 dest0, dest1;
+
+                    vdest = *(__m64 *)dst;
+
+                    dest0 = over(vsrc, vsrca, expand8888(vdest, 0));
+                    dest1 = over(vsrc, vsrca, expand8888(vdest, 1));
+
+                    *(__m64 *)dst = pack8888(dest0, dest1);
+
+                    dst += 2;
+                    w -= 2;
+                }
+
+                CHECKPOINT();
+
+                while (w)
+                {
+                    *dst = store8888(over(vsrc, vsrca, load8888(*dst)));
+
+                    w--;
+                    dst++;
+                }
+            }
+
+            _mm_empty();
+        }
+
+        _mm_empty();
+    }
+    else
+    {
+        fbCompositeSolid_nx8888mmx(op,
+            pSrc,
+            pMask,
+            pDst,
+            xSrc,
+            ySrc,
+            xMask,
+            yMask,
+            xDst,
+            yDst,
+            width,
+            height);
+    }
+#else
+    fbCompositeSolid_nx8888mmx(op,
+        pSrc,
+        pMask,
+        pDst,
+        xSrc,
+        ySrc,
+        xMask,
+        yMask,
+        xDst,
+        yDst,
+        width,
+        height);
+#endif
+}
+
+void
 fbCompositeSolid_nx0565mmx (pixman_op_t op,
 			    pixman_image_t * pSrc,
 			    pixman_image_t * pMask,
 			    pixman_image_t * pDst,
 			    int16_t	xSrc,
 			    int16_t	ySrc,
 			    int16_t	xMask,
 			    int16_t	yMask,
@@ -1435,16 +1659,19 @@ fbCompositeSrc_x888xnx8888mmx (pixman_op
 	    dst++;
 	    src++;
 	}
     }
 
     _mm_empty();
 }
 
+#define load8888(v) _mm_unpacklo_pi8(_mm_cvtsi32_si64(v), mZero)
+#define store8888(v) _mm_cvtsi64_si32(pack8888(v, mZero))
+
 void
 fbCompositeSrc_8888x8888mmx (pixman_op_t op,
 			     pixman_image_t * pSrc,
 			     pixman_image_t * pMask,
 			     pixman_image_t * pDst,
 			     int16_t	xSrc,
 			     int16_t	ySrc,
 			     int16_t      xMask,
@@ -1455,16 +1682,18 @@ fbCompositeSrc_8888x8888mmx (pixman_op_t
 			     uint16_t     height)
 {
     uint32_t	*dstLine, *dst;
     uint32_t	*srcLine, *src;
     uint32_t    s;
     int	dstStride, srcStride;
     uint8_t     a;
     uint16_t	w;
+    const __m64 mZero = _mm_setzero_si64();
+    const __m64 mmx_4x00ff = MC(4x00ff);
 
     CHECKPOINT();
 
     fbComposeGetStart (pDst, xDst, yDst, uint32_t, dstStride, dstLine, 1);
     fbComposeGetStart (pSrc, xSrc, ySrc, uint32_t, srcStride, srcLine, 1);
 
     while (height--)
     {
@@ -1479,24 +1708,27 @@ fbCompositeSrc_8888x8888mmx (pixman_op_t
 	    s = *src++;
 	    a = s >> 24;
 	    if (a == 0xff)
 		*dst = s;
 	    else if (a) {
 		__m64 ms, sa;
 		ms = load8888(s);
 		sa = expand_alpha(ms);
-		*dst = store8888(over(ms, sa, load8888(*dst)));
+		*dst = store8888(_mm_adds_pu8(ms, pix_multiply(load8888(*dst), _mm_xor_si64(sa, mmx_4x00ff))));
 	    }
 	    dst++;
 	}
     }
     _mm_empty();
 }
 
+#undef load8888
+#undef store8888
+
 void
 fbCompositeSrc_8888x0565mmx (pixman_op_t op,
 			     pixman_image_t * pSrc,
 			     pixman_image_t * pMask,
 			     pixman_image_t * pDst,
 			     int16_t      xSrc,
 			     int16_t      ySrc,
 			     int16_t      xMask,
@@ -1703,16 +1935,115 @@ fbCompositeSolidMask_nx8x8888mmx (pixman
 	    mask++;
 	    dst++;
 	}
     }
 
     _mm_empty();
 }
 
+#ifndef FbFullMask
+#define FbFullMask(n)   ((n) == 32 ? (uint32_t)-1 : ((((uint32_t) 1) << n) - 1))
+#endif
+extern uint32_t fbOver (uint32_t x, uint32_t y);
+extern uint32_t fbIn (uint32_t x, uint8_t y);
+
+void
+fbCompositeSolidMask_nx8x8888omp (pixman_op_t      op,
+			       pixman_image_t * pSrc,
+			       pixman_image_t * pMask,
+			       pixman_image_t * pDst,
+			       int16_t      xSrc,
+			       int16_t      ySrc,
+			       int16_t      xMask,
+			       int16_t      yMask,
+			       int16_t      xDst,
+			       int16_t      yDst,
+			       uint16_t     width,
+			       uint16_t     height)
+{
+#if defined(_OPENMP) && defined(_MSC_VER)
+    if (omp_cpu_counts >= 2 &&
+        width * height >= 150000)
+    {
+        uint32_t	 src, srca;
+        uint32_t	*dstLine, dstMask;
+        uint8_t	*maskLine;
+        int		 dstStride, maskStride;
+        int i;
+
+        fbComposeGetSolid(pSrc, src, pDst->bits.format);
+
+        dstMask = FbFullMask (PIXMAN_FORMAT_DEPTH (pDst->bits.format));
+        srca = src >> 24;
+        if (src == 0)
+      return;
+
+        fbComposeGetStart (pDst, xDst, yDst, uint32_t, dstStride, dstLine, 1);
+        fbComposeGetStart (pMask, xMask, yMask, uint8_t, maskStride, maskLine, 1);
+
+#pragma omp parallel for
+        for (i = 0; i < height; i++)
+        {
+            uint32_t *dst = dstLine + dstStride * i;
+            uint8_t *mask = maskLine + maskStride * i;
+            uint16_t w = width;
+            uint32_t d;
+            uint8_t m;
+
+            while (w--)
+            {
+                m = READ(pMask, mask++);
+                if (m == 0xff)
+                {
+                    if (srca == 0xff)
+                        WRITE(pDst, dst, src & dstMask);
+                    else
+                        WRITE(pDst, dst, fbOver (src, READ(pDst, dst)) & dstMask);
+                }
+                else if (m)
+                {
+                    d = fbIn (src, m);
+                    WRITE(pDst, dst, fbOver (d, READ(pDst, dst)) & dstMask);
+                }
+                dst++;
+            }
+        }
+    }
+    else
+    {
+        fbCompositeSolidMask_nx8x8888(op,
+            pSrc,
+            pMask,
+            pDst,
+            xSrc,
+            ySrc,
+            xMask,
+            yMask,
+            xDst,
+            yDst,
+            width,
+            height);
+    }
+#else
+    fbCompositeSolidMask_nx8x8888(op,
+        pSrc,
+        pMask,
+        pDst,
+        xSrc,
+        ySrc,
+        xMask,
+        yMask,
+        xDst,
+        yDst,
+        width,
+        height);
+#endif
+}
+
 pixman_bool_t
 pixman_fill_mmx (uint32_t *bits,
 		 int stride,
 		 int bpp,
 		 int x,
 		 int y,
 		 int width,
 		 int height,
@@ -2781,16 +3112,21 @@ fbCompositeSrcAdd_8888x8888mmx (pixman_o
 						 _mm_cvtsi32_si64(*dst)));
 
 	}
     }
 
     _mm_empty();
 }
 
+#ifdef TT_MEMUTIL
+extern pixman_bool_t nt_initialized;
+extern uint32_t dwNonTemporalDataSizeMin;
+#endif
+
 pixman_bool_t
 pixman_blt_mmx (uint32_t *src_bits,
 		uint32_t *dst_bits,
 		int src_stride,
 		int dst_stride,
 		int src_bpp,
 		int dst_bpp,
 		int src_x, int src_y,
@@ -2820,16 +3156,26 @@ pixman_blt_mmx (uint32_t *src_bits,
 	dst_bytes = (uint8_t *)(((uint32_t *)dst_bits) + dst_stride * (dst_y) + (dst_x));
 	byte_width = 4 * width;
 	src_stride *= 4;
 	dst_stride *= 4;
     } else {
 	return FALSE;
     }
 
+#ifdef TT_MEMUTIL
+    if (!nt_initialized)
+    {
+        dwNonTemporalDataSizeMin = GetNonTemporalDataSizeMin_tt();
+        nt_initialized = TRUE;
+    }
+
+if ((uint32_t)(byte_width * height) <= dwNonTemporalDataSizeMin)
+{
+#endif
     while (height--)
     {
 	int w;
 	uint8_t *s = src_bytes;
 	uint8_t *d = dst_bytes;
 	src_bytes += src_stride;
 	dst_bytes += dst_stride;
 	w = byte_width;
@@ -2911,16 +3257,87 @@ pixman_blt_mmx (uint32_t *src_bits,
 	if (w >= 2)
 	{
 	    *(uint16_t *)d = *(uint16_t *)s;
 	    w -= 2;
 	    s += 2;
 	    d += 2;
 	}
     }
+#ifdef TT_MEMUTIL
+}
+else
+{
+    while (height--)
+    {
+	int w;
+	uint8_t *s = src_bytes;
+	uint8_t *d = dst_bytes;
+	src_bytes += src_stride;
+	dst_bytes += dst_stride;
+	w = byte_width;
+
+	while (w >= 2 && ((unsigned long)d & 3))
+	{
+	    *(uint16_t *)d = *(uint16_t *)s;
+	    w -= 2;
+	    s += 2;
+	    d += 2;
+	}
+
+	while (w >= 4 && ((unsigned long)d & 7))
+	{
+	    *(uint32_t *)d = *(uint32_t *)s;
+
+	    w -= 4;
+	    s += 4;
+	    d += 4;
+	}
+
+	while (w >= 64)
+	{
+	    __m64 v0 = *(__m64 *)(s + 0);
+	    __m64 v1 = *(__m64 *)(s + 8);
+	    __m64 v2 = *(__m64 *)(s + 16);
+	    __m64 v3 = *(__m64 *)(s + 24);
+	    __m64 v4 = *(__m64 *)(s + 32);
+	    __m64 v5 = *(__m64 *)(s + 40);
+	    __m64 v6 = *(__m64 *)(s + 48);
+	    __m64 v7 = *(__m64 *)(s + 56);
+	    _mm_stream_pi((__m64*)(d +  0), v0);
+	    _mm_stream_pi((__m64*)(d +  8), v1);
+	    _mm_stream_pi((__m64*)(d + 16), v2);
+	    _mm_stream_pi((__m64*)(d + 24), v3);
+	    _mm_stream_pi((__m64*)(d + 32), v4);
+	    _mm_stream_pi((__m64*)(d + 40), v5);
+	    _mm_stream_pi((__m64*)(d + 48), v6);
+	    _mm_stream_pi((__m64*)(d + 56), v7);
+
+	    w -= 64;
+	    s += 64;
+	    d += 64;
+	}
+	while (w >= 4)
+	{
+	    *(uint32_t *)d = *(uint32_t *)s;
+
+	    w -= 4;
+	    s += 4;
+	    d += 4;
+	}
+	if (w >= 2)
+	{
+	    *(uint16_t *)d = *(uint16_t *)s;
+	    w -= 2;
+	    s += 2;
+	    d += 2;
+	}
+    }
+}
+#endif
 
     _mm_empty();
 
     return TRUE;
 }
 
 void
 fbCompositeCopyAreammx (pixman_op_t       op,
